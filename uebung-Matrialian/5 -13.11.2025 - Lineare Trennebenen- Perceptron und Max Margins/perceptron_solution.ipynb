{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70ab06b",
   "metadata": {},
   "source": [
    "# **KogSys-ML-B Introduction to Machine Learning**\n",
    "## **Perceptron**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc5b2a",
   "metadata": {},
   "source": [
    "To set up a new conda environment suitable for this notebook, you can use the following console commands:\n",
    "\n",
    "```bash\n",
    "conda create -y -n perc python=3.13\n",
    "conda activate perc\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Note**: Conda can become very hard-drive hungry when you use many environments. Consider regularly deleting environments you no longer need and running the ``conda clean --all`` command to remove no longer needed packages and cached files.\n",
    "\n",
    "You can also install the requirements for this notebook into an existing environment by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4ad8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9062ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc13f2",
   "metadata": {},
   "source": [
    "### **Implement a Perceptron**\n",
    "\n",
    "The goal is to implement an efficient thresholded perceptron using ``numpy``. For today, we will only be relying on ``scikit-learn`` for the ``ClassifierMixin`` base class for our perceptron (and for data management).\n",
    "\n",
    "We want our Perceptron to do the following things (in order of importance):\n",
    "1. Implement the Perceptron Training Rule and classify both _single and sets of samples_\n",
    "2. Automatically adapt to any input we pass as training data, i.e. do not have set a number of input features on construction\n",
    "3. Work with any class labels, i.e. no matter wether the classes are named ``0`` and ``1`` or \"apple\" and \"pear\"\n",
    "\n",
    "#### **$b$ or $w_0$?**\n",
    "\n",
    "You have to make a choice whether you want to implement the bias as a standalone additive factor, or as part of the weight vector. Both implementations have their advantages and drawbacks, neither is \"easier\" than the other. Whereas the $w_0$ approach requires you to make some data transformations within some (maybe just one?) of the methods for the approach to work, the $b$ approach will not cause you any troubles on that end, but requires some additional lines of code which are easily forgotten.\n",
    "\n",
    "For now: pick an option, and stick with it.\n",
    "\n",
    "#### **``forward`` and ``predict``**\n",
    "\n",
    "From our implementation of a Decision Tree ensemble in the third tutorial session, you know how the ``ClassifierMixin`` base class works, and that it requires the implementation of the ``predict`` method. For neural networks, it makes sense to add an intermediate method, the ``forward`` method. The ``forward`` method calculates the raw network output, whereas the ``predict`` method turns that output into a class prediction.\n",
    "\n",
    "Note how this relates to the third point of our implementation goal: The predict method works as a translator, turning the $+1$ and $-1$ network outputs into a prediction for arbitrary class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63944cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Class implementing a thresholded Perceptron using the w0 approach\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.__w: np.ndarray = np.random.randn(0)\n",
    "        self.__class_0: Any = 0\n",
    "        self.__class_1: Any = 1\n",
    "\n",
    "    @property\n",
    "    def w(self) -> np.ndarray:\n",
    "        return self.__w\n",
    "\n",
    "    def __init_weights(self, X: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Helper method to initialize weights. This is called from within fit if the dimensions of the input do not match the dimensions of the weights.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            A training sample from which the correct dimensionality will be infered.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.__w = np.random.randn(X.shape[-1] + 1)      # for the w0 approach, create a weight vector which is 1 larger than the number of attributes\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate the network output for input ``X``\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of network outputs.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.concatenate([np.ones(X.shape[:-1] + (1,)), X], axis = -1)\n",
    "\n",
    "        x = np.dot(X, self.__w)\n",
    "        x = np.array([x]) if not isinstance(x, np.ndarray) else x\n",
    "\n",
    "        x = np.array([1 if _x > 0 else -1 for _x in x])\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Turn the netweok output into a concept prediction of 1 or 0.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of concept predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.array([self.__class_1 if o == 1 else self.__class_0 for o in self.forward(X)])\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        lr: float = 0.001,\n",
    "        max_epoch: int = 500,\n",
    "        resume: bool = False,\n",
    "    ) -> Perceptron:\n",
    "        \"\"\"\n",
    "        Train the Perceptron on ``X`` labeled with ``y``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Training instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "        y: np.ndarrray\n",
    "            Labels. Must have exactly to classes, i.e. two distinct \n",
    "        lr: float (Optional)\n",
    "            Learning rate, default 0.001\n",
    "        max_epoch: int (Optional)\n",
    "            The maximum number of trianing epochs to run, default 500\n",
    "        resume: bool (Optional)\n",
    "            Resume training, i.e. do not initialize weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Perceptron\n",
    "            itself\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If ``X`` has an invalid number of dimensions.\n",
    "        ValueError\n",
    "            If ``y`` has an invalid number of classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure valid inputs\n",
    "        if X.ndim not in (1, 2):\n",
    "            raise ValueError(\n",
    "                f\"Invalid Dimension: X is of dimension {X.ndim}, but must be of dimension 1 for a single instance or 2 for a set of instances.\"\n",
    "            )\n",
    "        if len(np.unique(y)) != 2:\n",
    "            raise ValueError(\n",
    "                f\"Invalid number of classes: Requires 2 distinct classes in y but found {len(np.unique(y))}.\"\n",
    "            )\n",
    "        \n",
    "        self.__class_0, self.__class_1 = np.unique(y)\n",
    "\n",
    "        # re-initialize weights, if necessary\n",
    "        if X.shape[-1] != (self.__w.shape[0] - 1) and not resume:\n",
    "            self.__init_weights(X)\n",
    "\n",
    "        for _ in range(max_epoch):\n",
    "            for _x, _y in zip(X, y):\n",
    "                _y = -1 if _y == self.__class_0 else 1\n",
    "                self.__w += lr * (_y - self.forward(_x)) * np.concatenate([np.ones(_x.shape[:-1] + (1,)), _x], axis = -1)\n",
    "\n",
    "            if self.score(X, y) == 1:\n",
    "                break\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c295f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Class implementing a thresholded Perceptron using the bias approach\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.__w: np.ndarray = np.random.randn(0)\n",
    "        self.__b: np.ndarray = np.random.randn(1)\n",
    "        self.__class_0: Any = 0\n",
    "        self.__class_1: Any = 1\n",
    "\n",
    "    @property\n",
    "    def w(self) -> np.ndarray:\n",
    "        return self.__w\n",
    "\n",
    "    @property\n",
    "    def b(self) -> np.ndarray:\n",
    "        return self.__b\n",
    "\n",
    "    def __init_weights(self, X: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Helper method to initialize weights. This is called from within fit if the dimensions of the input do not match the dimensions of the weights.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            A training sample from which the correct dimensionality will be infered.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__w = np.random.randn(X.shape[-1])\n",
    "        self.__b = np.random.randn(1)\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate the network output for input ``X``\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of network outputs.\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.dot(X, self.__w) + self.__b\n",
    "\n",
    "        x = np.array([1 if _x > 0 else -1 for _x in x])\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Turn the netweok output into a concept prediction of 1 or 0.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of concept predictions.\n",
    "        \"\"\"\n",
    "        return np.array([self.__class_1 if o == 1 else self.__class_0 for o in self.forward(X)])\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        lr: float = 0.001,\n",
    "        max_epoch: int = 500,\n",
    "        resume: bool = False,\n",
    "    ) -> Perceptron:\n",
    "        \"\"\"\n",
    "        Train the Perceptron on ``X`` labeled with ``y``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Training instances, either one-dimensional for a single instance or 2-dimensional for a set of instances.\n",
    "        y: np.ndarrray\n",
    "            Labels. Must have exactly to classes, i.e. two distinct \n",
    "        lr: float (Optional)\n",
    "            Learning rate, default 0.001\n",
    "        max_epoch: int (Optional)\n",
    "            The maximum number of trianing epochs to run, default 500\n",
    "        resume: bool (Optional)\n",
    "            Resume training, i.e. do not initialize weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Perceptron\n",
    "            itself\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If ``X`` has an invalid number of dimensions.\n",
    "        ValueError\n",
    "            If ``y`` has an invalid number of classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure valid inputs\n",
    "        if X.ndim not in (1, 2):\n",
    "            raise ValueError(\n",
    "                f\"Invalid Dimension: X is of dimension {X.ndim}, but must be of dimension 1 for a single instance or 2 for a set of instances.\"\n",
    "            )\n",
    "        if len(np.unique(y)) != 2:\n",
    "            raise ValueError(\n",
    "                f\"Invalid number of classes: Requires 2 distinct classes in y but found {len(np.unique(y))}.\"\n",
    "            )\n",
    "        \n",
    "        self.__class_0, self.__class_1 = np.unique(y)\n",
    "\n",
    "        # re-initialize weights, if necessary\n",
    "        if X.shape[-1] != self.__w.shape[0] and not resume:\n",
    "            self.__init_weights(X)\n",
    "\n",
    "        for _ in range(max_epoch):\n",
    "            for _x, _y in zip(X, y):\n",
    "                _y = -1 if _y == self.__class_0 else 1\n",
    "                self.__w += lr * (_y - (o := self.forward(_x))) * _x\n",
    "                self.__b += lr * (_y - o)\n",
    "\n",
    "            if self.score(X, y) == 1:\n",
    "                break\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8413c4",
   "metadata": {},
   "source": [
    "### **Test Your Perceptron**\n",
    "\n",
    "You may leave the following two cells as they are. Your Perceptron should be able to classify this split of the ``iris`` dataset with perfect accuracy, taking essentially no time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085d1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y = True)\n",
    "\n",
    "y = np.array([1 if _y == 0 else 0 for _y in y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eefbcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "\n",
    "p = p.fit(X_train, y_train)\n",
    "p.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
