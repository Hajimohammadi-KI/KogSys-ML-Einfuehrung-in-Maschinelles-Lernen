{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"images/logo.png\" style=\"width : 100px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "_Abgabefrist: **18.01.2026**_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informationen zur Abgabe\n",
    "\n",
    "Laden Sie Ihre Lösung über den VC-Kurs hoch. Bitte laden Sie pro Gruppe **ein Zip-Archiv** hoch. Dieses muss enthalten:\n",
    "\n",
    "- Ihre Lösung als **Notebook** (eine `.inpynb` Datei)\n",
    "- Einen Ordner **images** mit allen Ihren Bildern (halten Sie die Größe der Bilder relativ klein)\n",
    "\n",
    "Ihre Zip-Datei sollte nach folgendem Schema benannt sein:\n",
    "\n",
    "```\n",
    "assignment_<assignment number>_solution_<group number>.zip\n",
    "```\n",
    "\n",
    "In diesem Assignment können Sie insgesamt **82** Punkte erreichen. Aus diesen Punkten berechnen sich **2,5 Bonuspunkte** für die Klausur wiefolgt:\n",
    "\n",
    "| **Punkte im Assignment** | **Bonuspunkte für die Klausur** |\n",
    "| :-: | :-: |\n",
    "| $78$ | $2.5$ |\n",
    "| $66$ | $2.0$ |\n",
    "| $54$ | $1.5$ |\n",
    "| $41$ | $1.0$ |\n",
    "| $29$ | $0.5$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-danger'>\n",
    "\n",
    "##### **Wichtige Hinweise**\n",
    "\n",
    "1. **Dieses Assignment wird benotet. Sie können Bonuspunkte für die Prüfung erhalten.**\n",
    "2. **Wenn es für uns offensichtlich ist, dass eine Aufgabe von einer anderen Quelle kopiert wurde und keine Eigenleistung erbracht wurde, vergeben wir keine Bonuspunkte. Formulieren Sie alle Antworten in eigenen Worten!**\n",
    "3. **Wenn LLMs (wie z.B. ChatGPT oder CoPilot) verwendet wurden, um Ihre Abgabe zu erstellen, geben Sie dies bitte an den jeweiligen Stellen an. Beachten Sie zudem die [AI-Policy](https://cogsys.uni-bamberg.de/teaching/ki-richtlinie.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements installieren\n",
    "\n",
    "Führe die nächste Zelle aus, um die Requirements zu installieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiert die benötigten Pakete mit dem akutell ausgewählten Python-Interpreter\n",
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 | Data Preprocessing\n",
    "\n",
    "_Für insgesamt **25** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Assignment arbeiten wir mit dem [Fruits-360 3-Body Problem](https://github.com/fruits-360/fruits-360-3-body-problem) Datensatz. Dieser Datensatz besteht aus 3 Klassen von Früchten.\n",
    "\n",
    "### **(03.1.0)** Datensatz herunterladen\n",
    "\n",
    "_Für **5** Extra-Punkte_\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Bitte gebt den Datensatz **NICHT** in eurer VC-Abgabe mit ab, das vergrößert eure Abgabe nur unnötig.\n",
    "\n",
    "</div>\n",
    "\n",
    "Ladet den Datensatz von GitHub unter `https://github.com/fruits-360/fruits-360-3-body-problem/archive/eed2e925766e61034e910da64f9119f19c057845.zip` in den `./data` Ordner herunter.\n",
    "Der `data` Ordner soll dann exakt das heruntergeladene Repository enthalten. So soll z.B. der Ordner `data/Test` oder `data/Train` direkt existieren.\n",
    "\n",
    "Verwendet exakt den verlinkten Datensatz!\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "\n",
    "Die Bearbeitung dieser Aufgabe ist komplett optional. Statt das Herunterladen des Datensatzes mit Code zu implementieren, könnt ihr auch einfach das ZIP-Archiv manuell herunterladen und korrekt entpacken.\n",
    "\n",
    "Wenn ihr diese Aufgabe allerdings **reproduzierbar** mithilfe von Python-Code bearbeitet, könnt ihr bis zu _5 Extra-Punkte_ erhalten. Diese werden auf eure Gesamtpunktzahl in diesem Assignment addiert und können somit zum ausgleichen anderer Fehler benutzt werden.\n",
    "\n",
    "**Ein Erreichen der Gesamtpunktzahl ist auch ohne diese _Extra-Punkte_ möglich!**\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Ihr möchtet die Aufgabe bearbeiten?</summary>\n",
    "\n",
    "Lade in der folgenden Code-Zelle den Datensatz von GitHub herunter.\n",
    "Hierzu musst du das ZIP-Archiv herunterladen, es entpacken und zusätzlich noch die Ordner-Struktur anpassen.\n",
    "\n",
    "Achtet darauf, dass euer Code auf Windows und macOS funktioniert!\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Download the Fruits-360 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.1.1)** Klassen-Labels definieren\n",
    "\n",
    "_Für **1** Punkt_\n",
    "\n",
    "**Definiere in der folgenden Code-Zelle eine Liste mit allen Labels der verfügbaren Klassen**\n",
    "\n",
    "Wenn z.B. die Verfügbaren Klassen `Banana`, `Pear` und `Lemon` wären, könnte die Liste `['Banana', 'Pear', 'Lemon']` lauten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.1.2)** `Dataset` Klasse Erstellen\n",
    "\n",
    "_Für **15** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle die `Dataset` Klasse für das Fruits-360 Dataset. Der Kopf der Klasse und des Konstruktors ist bereits vorgegeben, die Verwendung der Parameter ist im Docstring beschrieben.**\n",
    "\n",
    "**(9 Punkte) Konstruktor.**\n",
    "Im Konstruktor soll\n",
    "1. Das Root-Verzeichnis als Attribut abgespeichert werden\n",
    "2. Eine Liste aller Bild-Pfade und deren zugehörige Labels erstellt und als Attribute gespeichert werden.\n",
    "3. Aus der Menge der Trainingsbeispiele soll ein weiterer $10\\%$ großer Validierungs-Datensatz geteilt werden. Diese Teilung soll bei Anlegen des Datensatzes wiederholbar sein (entweder via `np.random.seed()` vor dem Teilen oder via `random_state` falls `sciki-learn` verwendet wird).\n",
    "4. In Abhängigkeit des `split` Parameters soll nur ein Split im Datensatz enthalten sein.\n",
    "5. Die `transform` und `label_transform` Callables sollen als Attribute gespeichert werden.\n",
    "\n",
    "**(5 Punkte) `__getitem__`.**\n",
    "In der `__getitem__` Methode soll in Abhängigkeit von `key : int` ein einziges Sample aus dem Datensatz zurückgegeben werden, als `tuple` bestehend aus dem Bild und Label.\n",
    "1. Lade das Bild mit Hilfe des gespeicherten Pfades (`PIL.Image.open()`). Verwende nach dem Laden noch `.convert('RGB')`, weil manche Bilder Schwarz-Weiß Bilder sein könnten.\n",
    "2. Das zugehörige Label aus der gespeicherten Liste holen.\n",
    "3. Wende die `Transform` Callables an. Du kannst die jeweiligen Attribute hier syntaktisch wie eine Funktion verwenden. Achte darauf, dass der Standardwert `None` ist. Ob die Callables belegt sind, solltest du vorher mit einer kurzen Bedingung überprüfen.\n",
    "\n",
    "**(1 Punkt) `__len__`.**\n",
    "Implementiere die `__len__` Methode, die die Anzahl an Beispielen im `Dataset` als `int` zurückgibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung: Validierungsdatensatz.** Bei Datensätzen die als _Benchmark_ verwendet werden sollen, wird der Testdatensatz häufig entweder ohne Labels oder gar nicht zur Verfügung gestellt. Das wird gemacht, damit das Modell nicht auf den Testdaten trainieren kann, um in den Leaderboards zu schummeln. Der Testdatensatz des Fruits-360 Datasets wird hier als finaler Evaluierungsdatensatz verwendet.  \n",
    "Wir sollten einen eigenen _Validierungsdatensatz_ aus dem Trainingsdatensatz herausbrechen, um während des Trainings die Modellleistung zu überwachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "\n",
    "class Fruits360(tdata.Dataset):\n",
    "    '''\n",
    "    torch dataset for the Fruits-360 dataset\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root : str, split : str = 'train', transform : Callable = None, label_transform : Callable = None):\n",
    "        ''' 9 Punkte\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        - root (str) : path to the to root directory of the dataset\n",
    "        - split (str) : one of 'train', 'val', or 'test'. Should decide which split of the dataset to return.\n",
    "        - transform (Callable) : transform callable to apply to the images\n",
    "        - label_transform (Callable) : transform callable to apply to the labels\n",
    "        '''\n",
    "\n",
    "        # TODO: Implement constructor\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __getitem__(self, key : int) -> tuple:\n",
    "        ''' 5 Punkte\n",
    "        '''\n",
    "\n",
    "        # TODO: Implement __getitem__\n",
    "        pass\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        ''' 2 Punkte\n",
    "        '''\n",
    "        # TODO: Implement __len__\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.1.3)** `Transform` Klassen und `Compose` Erstellen\n",
    "\n",
    "_Für **6** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementiere die `Transform` Callables, die dem Dataset als die `transform` und `label_transform` Parameter übergeben werden.**\n",
    "\n",
    "1. **(2 Punkte)** Für `label_transform`, lege eine Klasse an, die die `str` Labels aus dem Dataframe zu Integer-Tensors umwandelt. Du kannst dafür je nach Implementation des Datensatzes die `codes` oder `values` Liste verwenden, in der die Klassennamen stehen. Die Klasse muss die `__call__` Methode implementieren, die das Verhalten eines Objektes festlegt, wenn es wie eine Funktion aufgerufen wird.\n",
    "2. **(4 Punkte)** Für `transform` soll das geladene `Image` zu einem Tensor im PyTorch-Format `(c, h, w)` umgewandelt werden, und anschließend zur Auflösung `128x128` skaliert werden. Verwende dafür den `transforms.Compose` Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "class ConvertLabel(object):\n",
    "    ''' 2 Punkte\n",
    "    callable object converting a label to an integer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, labels):\n",
    "        # TODO: Implement constructor\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample : str) -> torch.Tensor:\n",
    "        # TODO: Implement __call__\n",
    "        pass\n",
    "    \n",
    "\n",
    "# TODO: Implement fruits360_transforms using transforms.Compose\n",
    "fruits360_transforms = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.1.4)** `DataLoader` Erstellen\n",
    "\n",
    "_Für **3** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lege `DataLoader` für die Trainings-, Validierungs- und Test-Splits an. Achte jedenfalls beim Validierungs-Loader darauf, dass die Samples bei jeder Iteration durch den DataLoader in der gleichen Reihenfolge gezogen werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create train_loader\n",
    "\n",
    "# TODO: Create val_loader\n",
    "\n",
    "# TODO: Create test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 | Convolutional Neural Networks\n",
    "\n",
    "_Für insgesamt **35** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.2.1)** Netzwerk Erstellen\n",
    "\n",
    "_Für **10** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementiere ein Neuronales Netzwerk bestehend aus Blöcken des `torch.nn` Moduls, dem `BasicBlock` aus `torchvision.models.resnet` und möglicherweise selbst implementierten oder angepassten Blöcken _(5 Punkte)_.**\n",
    "\n",
    "**Weitere Punkte dieser Aufgabe werden für das einhalten der folgenden Anforderungen vergeben:**\n",
    "- **(3 Punkte):** Das Modell soll weniger als $100,000$ Parameter haben. Je nach Höhe der Überschreitung werden Punkte abgezogen  \n",
    "($<100,000$ -0 Punkte, $100,000 - 120,000$ -1 Punkt, $120,000-140,000$ -2 Punkte, $>140,000$ -3 Punkte).\n",
    "- **(2 Punkte):** Das Modell soll auf dem Test-Split des Datensatzes eine Accuracy von mindestens $.55$ erreichen (im Rahmen der Vorgaben der nächsten Aufgabe). Je nach Höhe der Unterschreitung werden Punkte abgezogen  \n",
    "($>.55$ -0 Punkte, $.55-.5$ -1 Punkt, $<.5$ -2 Punkte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "# Hey! You should really read the code of \"BasicBlock\" to get a\n",
    "# better understanding of the architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Implement your model architecture\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.2.2)** Netzwerk Trainieren\n",
    "\n",
    "_Für **23** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementiert einen Trainingsloop für das oben entworfene Netzwerk. Punkte für diese Aufgabe werden für die Implementation folgender Komponenten vergeben:**\n",
    "\n",
    "1. **(11 Punkte) Training Generell.** Generell benötigt ein Trainingsloop für ein `PyTorch` Netzwerk einen `Optimizer` und eine Loss-Funktion. Während dem Training soll...\n",
    "   - Modell und Daten auf dem gleichen (stärksten) Gerät liegen\n",
    "   - das Modell in den Trainingsmodus gesetzt werden\n",
    "   - durch den Trainings `DataLoader` iteriert werden\n",
    "   - für jeden Batch die Gradients im Optimizer auf 0 gesetzt werden\n",
    "   - die Outputs für den Batch...\n",
    "   - und damit und mit den Labels die Loss-Funktion berechnet werden\n",
    "   - der Loss rückpropagiert werden\n",
    "   - ein Optimierungsschritt durchgeführt werden\n",
    "2. **(5 Punkte) Validierung.** Auf dem in Aufgabe **03.1.1** erstellten Validierungs-Split soll am Ende jeder Trainigns-Epoche das aktuelle Modell evaluiert werden. Dafür soll...\n",
    "   - das Modell in den Evaluierungsmodus gesetzt werden\n",
    "   - die Berechnung der Gradients ausgeschaltet werden\n",
    "   - die Accuracy des Modells für den Validierungs `DataLoader` berechnet werden\n",
    "3. **(3 Punkte) Learning-Rate Scheduling.** Mit Hilfe des `torch.optim.lr_scheduler.ReduceLROnPlateau` Learning-Rate Schedulers soll die Learning-Rate des Optimizers dann reduziert werden, wenn sich eine Metrik nicht mehr verbessert. Wählt eine sinnvolle Metrik und Patience und baut den Learning-Rate Scheduler in euren Trainingsloop ein.\n",
    "4. **(4 Punkte) Early-Stopping und Checkpointing.** Das Training soll unterbrochen werden, wenn sich eine Metrik nicht mehr verbessert. wählt eine sinnvolle Metrik und Patience und baut eine Bedingung für Early-Stopping in euren Trainings-Loop ein. Stellt sicher, dass wenn das Training durch Early-Stopping beendet wird auch das beste, _nicht das aktuellste_ Modell verwendet wird. Die Modelle, mit denen ihr arbeitet, sind klein genug, dass potentiell jede Epoche ein Checkpoint angelegt werden könnte.\n",
    "\n",
    "**Experimentiert mit Parametern und weiteren Techniken, um euer Modell so effizient wie möglich zu trainieren. Es kann außerdem hilfreich und anschaulich sein, wichtige Metriken während dem Training auf die Konsole zu drucken, um den Trainingsfortschritt nachzuvollziehen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-warning'>\n",
    "\n",
    "**Achtung: Zum Erreichen der Accuracy-Vorgabe der vorherigen Aufgabe darf das Modell für _maximal 25 Epochen_ trainiert werden.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "\n",
    "##### **Performance Hinweis: [Google Colab](https://colab.research.google.com)**\n",
    "\n",
    "***Das Training von Netzwerken dieser Größe ist sehr rechenaufwändig. Beim Training auf der CPU ist die Trainingszeit so lang, dass das Experimentieren mit verschiedenen Architekturen erschwert wird (weil sehr lange auf Ergebnisse gewartet werden muss). Ihr könnt die Trainingszeit beschleunigen, indem ihr euer Training auf Google Colab ausführt. Bereits der kostenlose GPU Zugriff sollte ausreichen um die Trainingszeit auf unter 10 Minuten zu reduzieren. Es ist auch zu empfehlen, beim testen der Architekturen mit weniger Trainingsepochen zu arbeiten.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# TODO: Implement training loop with:\n",
    "# - Optimizer and loss function\n",
    "# - Training on the device\n",
    "# - Validation after each epoch\n",
    "# - Learning rate scheduling\n",
    "# - Early stopping and checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.2.3)** Netzwerk Evaluieren\n",
    "\n",
    "_Für **2** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berechne die Accuracy des trainierten Netzwerks auf dem Vordefinierten Validierungssplit (hier Test-Split) des Fruits-360 Datensatzes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "\n",
    "##### **Abgabe-Hinweis: Model Checkpoint**\n",
    "\n",
    "**Es ist zulässig, einen Modell-Checkpoint in der Zip-Datei mit abzugeben, um die Replizierbarkeit eurer Ergebnisse sicherzustellen. In diesem Fall muss das Laden des Checkpoints in diesem Notebook fertig implementiert und funktionsfähig sein.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement test evaluation to calculate accuracy on test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 | Netzwerkanalyse\n",
    "\n",
    "_Für insgesamt **22** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachte das folgende Neuronale Netzwerk zur Klassifikation von RGB-Bildern der Auflösung $96\\times96$ und $8$ Klassen:\n",
    "\n",
    "1. Convolution Layer mit $3$ input channels und $24$ output channels, kernel size $5$, stride $1$, padding $2$, groups $1$ und keinem Bias.\n",
    "2. ReLU\n",
    "3. MaxPooling Layer mit kernel size $2$\n",
    "4. Convolution Layer mit $24$ input channels und $48$ output channels, kernel size $3$, stride $1$, padding $1$, groups $3$ und keinem Bias.\n",
    "5. ReLU\n",
    "6. Convolution Layer mit $48$ input channels und $48$ output channels, kernel size $3$, stride $2$, padding $1$, groups $1$ und keinem Bias.\n",
    "7. ReLU\n",
    "8. Convolution Layer mit $48$ input channels und $64$ output channels, kernel size $3$, stride $1$, padding $1$, groups $4$ und keinem Bias.\n",
    "9. ReLU\n",
    "10. MaxPooling Layer mit kernel size $2$\n",
    "11. Convolution Layer mit $64$ input channels und $64$ output channels, kernel size $3$, stride $1$, padding $1$, groups $8$ und keinem Bias.\n",
    "12. ReLU\n",
    "13. Flattening Layer\n",
    "14. Linear Layer mit $\\fbox{???}$ input features und $512$ output features und keinem Bias.\n",
    "15. ReLU\n",
    "16. Linear Layer mit $512$ input features und $128$ output features und keinem Bias.\n",
    "17. ReLU\n",
    "18. Linear Layer mit $128$ input features und $32$ output featuers und keinem Bias.\n",
    "19. ReLU\n",
    "20. Linear Layer mit $32$ input features und $8$ output features und keinem Bias.\n",
    "21. Softmax Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.3.1)** Wie viele Input Features muss das erste Linear Layer (Layer 14) des oben beschriebenen Netzwerks haben? Erkläre auch, wie sich die Zahl berechnet.\n",
    "\n",
    "_Für **4** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.3.2)** Zeichne ein Netzwerkdiagramm des oben beschriebenen Netzwerks. Beschrifte das Diagramm mit den korrekten Dimensionen beim Input und nach jedem Layer, in dem sich die Dimensionen verändern.\n",
    "\n",
    "_Für **8** Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(03.3.3)** Berechne die Parameterzahl des oben beschriebenen Netzwerks. Achte auch auf Nachvollziehbarkeit des Rechenweges.\n",
    "\n",
    "_Für 10 Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-pro (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
