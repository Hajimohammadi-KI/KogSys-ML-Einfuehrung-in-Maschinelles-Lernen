{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e4ff87",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "_Submission Deadline: **18.01.2026**_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc5e5e",
   "metadata": {},
   "source": [
    "#### Submission Information\n",
    "\n",
    "Upload your solution via the VC course. Please upload **one Zip archive** per group. This must contain:\n",
    "\n",
    "- Your solution as a **Notebook** (an `.ipynb` file)\n",
    "- An **images** folder with all your images (keep the size of the images relatively small)\n",
    "\n",
    "Your Zip file should be named according to the following schema:\n",
    "\n",
    "```\n",
    "assignment_<assignment number>_solution_<group number>.zip\n",
    "```\n",
    "\n",
    "In this assignment, you can achieve a total of **82** points. From these points, **2.5 bonus points** for the exam are calculated as follows:\n",
    "\n",
    "| **Points in Assignment** | **Bonus Points for Exam** |\n",
    "| :-: | :-: |\n",
    "| $78$ | $2.5$ |\n",
    "| $66$ | $2.0$ |\n",
    "| $54$ | $1.5$ |\n",
    "| $41$ | $1.0$ |\n",
    "| $29$ | $0.5$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee50514",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-danger'>\n",
    "\n",
    "##### **Important Notes**\n",
    "\n",
    "1. **This assignment is graded. You can receive bonus points for the exam.**\n",
    "2. **If it is obvious to us that a task was copied from another source and no original work was performed, we will not award bonus points. Formulate all answers in your own words!**\n",
    "3. **If LLMs (such as ChatGPT or CoPilot) were used to create your submission, please indicate this in the respective places. Also note the [AI Policy](https://cogsys.uni-bamberg.de/teaching/ki-richtlinie.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef11d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab37ac",
   "metadata": {},
   "source": [
    "#### Install Requirements\n",
    "\n",
    "Run the next cell to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c13eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==2.3.5 (from -r requirements.txt (line 1))\n",
      "  Downloading numpy-2.3.5-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pillow==12.0.0 (from -r requirements.txt (line 2))\n",
      "  Downloading pillow-12.0.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting torch==2.9.1 (from -r requirements.txt (line 3))\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision==0.24.1 (from -r requirements.txt (line 4))\n",
      "  Downloading torchvision-0.24.1-cp313-cp313-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Collecting scikit-learn==1.8.0 (from -r requirements.txt (line 6))\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 3)) (70.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from scikit-learn==1.8.0->-r requirements.txt (line 6)) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from scikit-learn==1.8.0->-r requirements.txt (line 6)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from scikit-learn==1.8.0->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elahe\\python\\minianacoda\\lib\\site-packages (from jinja2->torch==2.9.1->-r requirements.txt (line 3)) (2.1.5)\n",
      "Downloading numpy-2.3.5-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.8/12.8 MB 38.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 37.0 MB/s  0:00:00\n",
      "Downloading pillow-12.0.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 36.8 MB/s  0:00:00\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 7.1/110.9 MB 35.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 14.2/110.9 MB 34.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 21.5/110.9 MB 35.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 28.0/110.9 MB 35.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 34.3/110.9 MB 34.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 41.7/110.9 MB 34.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 49.3/110.9 MB 35.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 55.6/110.9 MB 34.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 62.7/110.9 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 70.0/110.9 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 78.9/110.9 MB 35.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 86.0/110.9 MB 35.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 94.1/110.9 MB 35.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 103.3/110.9 MB 36.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 36.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 35.3 MB/s  0:00:03\n",
      "Downloading torchvision-0.24.1-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 40.0 MB/s  0:00:00\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 6.8/8.0 MB 42.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 32.7 MB/s  0:00:00\n",
      "Installing collected packages: pillow, numpy, torch, torchvision, scikit-learn\n",
      "\n",
      "  Attempting uninstall: pillow\n",
      "\n",
      "    Found existing installation: pillow 11.3.0\n",
      "\n",
      "    Uninstalling pillow-11.3.0:\n",
      "\n",
      "      Successfully uninstalled pillow-11.3.0\n",
      "\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "  Attempting uninstall: numpy\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "    Found existing installation: numpy 2.3.3\n",
      "   ---------------------------------------- 0/5 [pillow]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "    Uninstalling numpy-2.3.3:\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.3\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "  Attempting uninstall: torch\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "    Found existing installation: torch 2.9.0+cu128\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "    Uninstalling torch-2.9.0+cu128:\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "      Successfully uninstalled torch-2.9.0+cu128\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "  Attempting uninstall: torchvision\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "    Found existing installation: torchvision 0.24.0+cu128\n",
      "   ---------------- ----------------------- 2/5 [torch]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "    Uninstalling torchvision-0.24.0+cu128:\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "      Successfully uninstalled torchvision-0.24.0+cu128\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "  Attempting uninstall: scikit-learn\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "    Found existing installation: scikit-learn 1.7.2\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "    Uninstalling scikit-learn-1.7.2:\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "      Successfully uninstalled scikit-learn-1.7.2\n",
      "   ------------------------ --------------- 3/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [scikit-learn]\n",
      "   ---------------------------------------- 5/5 [scikit-learn]\n",
      "\n",
      "Successfully installed numpy-2.3.5 pillow-12.0.0 scikit-learn-1.8.0 torch-2.9.1 torchvision-0.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "torchaudio 2.9.0 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Installs the required packages with the currently selected Python interpreter\n",
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975995c",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 | Data Preprocessing\n",
    "\n",
    "_For a total of **25** points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1759a",
   "metadata": {},
   "source": [
    "In this assignment, we work with the [Fruits-360 3-Body Problem](https://github.com/fruits-360/fruits-360-3-body-problem) dataset. This dataset consists of 3 classes of fruits.\n",
    "\n",
    "### **(03.1.0)** Download Dataset\n",
    "\n",
    "_For **5** Extra Points_\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Please do **NOT** include the dataset in your VC submission, this only unnecessarily increases the size of your submission.\n",
    "\n",
    "</div>\n",
    "\n",
    "Download the dataset from GitHub at `https://github.com/fruits-360/fruits-360-3-body-problem/archive/eed2e925766e61034e910da64f9119f19c057845.zip` into the `./data` folder.\n",
    "The `data` folder should then contain exactly the downloaded repository. For example, the folder `data/Test` or `data/Train` should exist directly.\n",
    "\n",
    "Use exactly the linked dataset!\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "\n",
    "Working on this task is completely optional. Instead of implementing the dataset download with code, you can also simply download the ZIP archive manually and unpack it correctly.\n",
    "\n",
    "However, if you solve this task **reproducibly** using Python code, you can receive up to _5 extra points_. These will be added to your total score in this assignment and can thus be used to compensate for other mistakes.\n",
    "\n",
    "**Reaching the total score is also possible without these _extra points_!**\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Do you want to work on the task?</summary>\n",
    "\n",
    "Download the dataset from GitHub in the following code cell.\n",
    "To do this, you must download the ZIP archive, unpack it, and additionally adjust the folder structure.\n",
    "\n",
    "Make sure your code works on Windows and macOS!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc0cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Download the Fruits-360 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788e201",
   "metadata": {},
   "source": [
    "### **(03.1.1)** Define Class Labels\n",
    "\n",
    "_For **1** Point_\n",
    "\n",
    "**Define a list with all labels of the available classes in the following code cell**\n",
    "\n",
    "For example, if the available classes were `Banana`, `Pear`, and `Lemon`, the list could be `['Banana', 'Pear', 'Lemon']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157503b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b01e38",
   "metadata": {},
   "source": [
    "### **(03.1.2)** Create `Dataset` Class\n",
    "\n",
    "_For **15** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94029f83",
   "metadata": {},
   "source": [
    "**Create the `Dataset` class for the Fruits-360 dataset. The header of the class and the constructor are already given, the usage of the parameters is described in the docstring.**\n",
    "\n",
    "**(9 Points) Constructor.**\n",
    "In the constructor:\n",
    "1. The root directory should be stored as an attribute.\n",
    "2. A list of all image paths and their corresponding labels should be created and stored as attributes.\n",
    "3. A further $10\\%$ large validation dataset should be split from the set of training examples. This split should be reproducible when creating the dataset (either via `np.random.seed()` before splitting or via `random_state` if `scikit-learn` is used).\n",
    "4. Depending on the `split` parameter, only one split should be contained in the dataset.\n",
    "5. The `transform` and `label_transform` callables should be stored as attributes.\n",
    "\n",
    "**(5 Points) `__getitem__`.**\n",
    "In the `__getitem__` method, a single sample from the dataset should be returned depending on `key : int`, as a `tuple` consisting of the image and label.\n",
    "1. Load the image using the stored path (`PIL.Image.open()`). Use `.convert('RGB')` after loading, because some images might be black and white images.\n",
    "2. Get the corresponding label from the stored list.\n",
    "3. Apply the `Transform` callables. You can use the respective attributes syntactically like a function here. Make sure that the default value is `None`. You should check beforehand with a short condition whether the callables are assigned.\n",
    "\n",
    "**(1 Point) `__len__`.**\n",
    "Implement the `__len__` method, which returns the number of examples in the `Dataset` as `int`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582b676",
   "metadata": {},
   "source": [
    "**Note: Validation Dataset.** For datasets that are to be used as a _benchmark_, the test dataset is often provided either without labels or not at all. This is done so that the model cannot train on the test data to cheat in the leaderboards. The test dataset of the Fruits-360 dataset is used here as the final evaluation dataset.\n",
    "We should break out our own _validation dataset_ from the training dataset to monitor model performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17aaa678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "\n",
    "class Fruits360(tdata.Dataset):\n",
    "    '''\n",
    "    torch dataset for the Fruits-360 dataset\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root : str, split : str = 'train', transform : Callable = None, label_transform : Callable = None):\n",
    "        ''' 9 Points\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        - root (str) : path to the to root directory of the dataset\n",
    "        - split (str) : one of 'train', 'val', or 'test'. Should decide which split of the dataset to return.\n",
    "        - transform (Callable) : transform callable to apply to the images\n",
    "        - label_transform (Callable) : transform callable to apply to the labels\n",
    "        '''\n",
    "\n",
    "        # TODO: Implement constructor\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __getitem__(self, key : int) -> tuple:\n",
    "        ''' 5 Points\n",
    "        '''\n",
    "\n",
    "        # TODO: Implement __getitem__\n",
    "        pass\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        ''' 2 Points\n",
    "        '''\n",
    "        # TODO: Implement __len__\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a2b28",
   "metadata": {},
   "source": [
    "### **(03.1.3)** Create `Transform` Classes and `Compose`\n",
    "\n",
    "_For **6** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8415fa",
   "metadata": {},
   "source": [
    "**Implement the `Transform` callables that are passed to the dataset as the `transform` and `label_transform` parameters.**\n",
    "\n",
    "1. **(2 Points)** For `label_transform`, create a class that converts the `str` labels from the dataframe to integer tensors. Depending on the implementation of the dataset, you can use the `codes` or `values` list containing the class names. The class must implement the `__call__` method, which defines the behavior of an object when it is called like a function.\n",
    "2. **(4 Points)** For `transform`, the loaded `Image` should be converted to a tensor in PyTorch format `(c, h, w)`, and then scaled to the resolution `128x128`. Use the `transforms.Compose` container for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784066dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "class ConvertLabel(object):\n",
    "    ''' 2 Points\n",
    "    callable object converting a label to an integer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, labels):\n",
    "        # TODO: Implement constructor\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample : str) -> torch.Tensor:\n",
    "        # TODO: Implement __call__\n",
    "        pass\n",
    "    \n",
    "\n",
    "# TODO: Implement fruits360_transforms using transforms.Compose\n",
    "fruits360_transforms = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2701e",
   "metadata": {},
   "source": [
    "### **(03.1.4)** Create `DataLoader`\n",
    "\n",
    "_For **3** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbae5f",
   "metadata": {},
   "source": [
    "**Create `DataLoader` for the training, validation, and test splits. In any case, make sure for the validation loader that the samples are drawn in the same order during each iteration through the DataLoader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88669cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create train_loader\n",
    "\n",
    "# TODO: Create val_loader\n",
    "\n",
    "# TODO: Create test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2da26",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 | Convolutional Neural Networks\n",
    "\n",
    "_For a total of **35** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c6543",
   "metadata": {},
   "source": [
    "### **(03.2.1)** Create Network\n",
    "\n",
    "_For **10** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e643ae",
   "metadata": {},
   "source": [
    "**Implement a neural network consisting of blocks from the `torch.nn` module, the `BasicBlock` from `torchvision.models.resnet`, and possibly self-implemented or adapted blocks _(5 Points)_.**\n",
    "\n",
    "**Further points for this task are awarded for complying with the following requirements:**\n",
    "- **(3 Points):** The model should have fewer than $100,000$ parameters. Points will be deducted depending on the amount of excess\n",
    "($<100,000$ -0 Points, $100,000 - 120,000$ -1 Point, $120,000-140,000$ -2 Points, $>140,000$ -3 Points).\n",
    "- **(2 Points):** The model should achieve an accuracy of at least $.55$ on the test split of the dataset (within the framework of the requirements of the next task). Points will be deducted depending on the amount of shortfall\n",
    "($>.55$ -0 Points, $.55-.5$ -1 Point, $<.5$ -2 Points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf68676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "# Hey! You should really read the code of \"BasicBlock\" to get a\n",
    "# better understanding of the architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e2fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Implement your model architecture\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2893f5c",
   "metadata": {},
   "source": [
    "### **(03.2.2)** Train Network\n",
    "\n",
    "_For **23** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc976d75",
   "metadata": {},
   "source": [
    "**Implement a training loop for the network designed above. Points for this task are awarded for the implementation of the following components:**\n",
    "\n",
    "1. **(11 Points) Training General.** Generally, a training loop for a `PyTorch` network requires an `Optimizer` and a loss function. During training...\n",
    "   - Model and data should be on the same (strongest) device\n",
    "   - the model should be set to training mode\n",
    "   - iterate through the training `DataLoader`\n",
    "   - for each batch, the gradients in the optimizer should be set to 0\n",
    "   - the outputs for the batch...\n",
    "   - and with them and the labels, the loss function should be calculated\n",
    "   - the loss should be backpropagated\n",
    "   - an optimization step should be performed\n",
    "2. **(5 Points) Validation.** At the end of each training epoch, the current model should be evaluated on the validation split created in task **03.1.1**. For this...\n",
    "   - the model should be set to evaluation mode\n",
    "   - the calculation of gradients should be turned off\n",
    "   - the accuracy of the model for the validation `DataLoader` should be calculated\n",
    "3. **(3 Points) Learning-Rate Scheduling.** Using the `torch.optim.lr_scheduler.ReduceLROnPlateau` learning rate scheduler, the learning rate of the optimizer should be reduced when a metric no longer improves. Choose a meaningful metric and patience and build the learning rate scheduler into your training loop.\n",
    "4. **(4 Points) Early-Stopping and Checkpointing.** Training should be interrupted if a metric no longer improves. Choose a meaningful metric and patience and build a condition for early stopping into your training loop. Ensure that if training is terminated by early stopping, the best, _not the most recent_ model is used. The models you are working with are small enough that potentially a checkpoint could be created every epoch.\n",
    "\n",
    "**Experiment with parameters and other techniques to train your model as efficiently as possible. It can also be helpful and illustrative to print important metrics to the console during training to track training progress.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e6913a",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-warning'>\n",
    "\n",
    "**Attention: To achieve the accuracy requirement of the previous task, the model may be trained for _a maximum of 25 epochs_.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3ef59",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "\n",
    "##### **Performance Note: [Google Colab](https://colab.research.google.com)**\n",
    "\n",
    "***Training networks of this size is very computationally intensive. When training on the CPU, the training time is so long that experimenting with different architectures is made difficult (because one has to wait very long for results). You can speed up the training time by running your training on Google Colab. Even the free GPU access should be sufficient to reduce the training time to under 10 minutes. It is also recommended to work with fewer training epochs when testing architectures.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318a57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# TODO: Implement training loop with:\n",
    "# - Optimizer and loss function\n",
    "# - Training on the device\n",
    "# - Validation after each epoch\n",
    "# - Learning rate scheduling\n",
    "# - Early stopping and checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c16a75",
   "metadata": {},
   "source": [
    "### **(03.2.3)** Evaluate Network\n",
    "\n",
    "_For **2** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c1aff",
   "metadata": {},
   "source": [
    "**Calculate the accuracy of the trained network on the predefined validation split (here test split) of the Fruits-360 dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4a0db",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "\n",
    "##### **Submission Note: Model Checkpoint**\n",
    "\n",
    "**It is permissible to submit a model checkpoint in the Zip file to ensure the reproducibility of your results. In this case, the loading of the checkpoint must be fully implemented and functional in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29b6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement test evaluation to calculate accuracy on test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fe4b2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 | Network Analysis\n",
    "\n",
    "_For a total of **22** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d6719",
   "metadata": {},
   "source": [
    "Consider the following neural network for the classification of RGB images with a resolution of $96\\times96$ and $8$ classes:\n",
    "\n",
    "1. Convolution Layer with $3$ input channels and $24$ output channels, kernel size $5$, stride $1$, padding $2$, groups $1$ and no bias.\n",
    "2. ReLU\n",
    "3. MaxPooling Layer with kernel size $2$\n",
    "4. Convolution Layer with $24$ input channels and $48$ output channels, kernel size $3$, stride $1$, padding $1$, groups $3$ and no bias.\n",
    "5. ReLU\n",
    "6. Convolution Layer with $48$ input channels and $48$ output channels, kernel size $3$, stride $2$, padding $1$, groups $1$ and no bias.\n",
    "7. ReLU\n",
    "8. Convolution Layer with $48$ input channels and $64$ output channels, kernel size $3$, stride $1$, padding $1$, groups $4$ and no bias.\n",
    "9. ReLU\n",
    "10. MaxPooling Layer with kernel size $2$\n",
    "11. Convolution Layer with $64$ input channels and $64$ output channels, kernel size $3$, stride $1$, padding $1$, groups $8$ and no bias.\n",
    "12. ReLU\n",
    "13. Flattening Layer\n",
    "14. Linear Layer with $\\fbox{???}$ input features and $512$ output features and no bias.\n",
    "15. ReLU\n",
    "16. Linear Layer with $512$ input features and $128$ output features and no bias.\n",
    "17. ReLU\n",
    "18. Linear Layer with $128$ input features and $32$ output features and no bias.\n",
    "19. ReLU\n",
    "20. Linear Layer with $32$ input features and $8$ output features and no bias.\n",
    "21. Softmax Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1756dd",
   "metadata": {},
   "source": [
    "### **(03.3.1)** How many input features must the first Linear Layer (Layer 14) of the network described above have? Also explain how the number is calculated.\n",
    "\n",
    "_For **4** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd1da7",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69fdb0",
   "metadata": {},
   "source": [
    "### **(03.3.2)** Draw a network diagram of the network described above. Label the diagram with the correct dimensions at the input and after each layer where the dimensions change.\n",
    "\n",
    "_For **8** Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f0c0d",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a0e8f",
   "metadata": {},
   "source": [
    "### **(03.3.3)** Calculate the number of parameters of the network described above. Also ensure that the calculation path is comprehensible.\n",
    "\n",
    "_For 10 Points_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c66d67",
   "metadata": {},
   "source": [
    "\n",
    "> ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
