{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo.png\" style=\"width: 100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### Entscheidungsbäume, K-Fold-Cross-Validation und ILP\n",
    "\n",
    "_Abgabefrist: **23.11.2025**_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informationen zur Abgabe\n",
    "\n",
    "Laden Sie Ihre Lösung über den VC-Kurs hoch. Bitte laden Sie pro Gruppe **ein Zip-Archiv** hoch. Dieses muss enthalten:\n",
    "\n",
    "- Ihre Lösung als **Notebook** (eine `.inpynb` Datei) und/oder ggf. Python Dateien (`.py`).\n",
    "- Einen Ordner **images** mit allen Ihren Bildern (halten Sie die Größe der Bilder relativ klein)\n",
    "\n",
    "Ihre Zip-Datei sollte nach folgendem Schema benannt sein:\n",
    "\n",
    "```\n",
    "assignment_<assignment number>_solution_<group number>.zip\n",
    "```\n",
    "\n",
    "In diesem Assignment können Sie insgesamt **62** Punkte erreichen. Aus diesen Punkten berechnen sich **2,5 Bonuspunkte** für die Klausur wiefolgt:\n",
    "\n",
    "| **Punkte im Assignment** | **Bonuspunkte für die Klausur** |\n",
    "| :-: | :-: |\n",
    "| 59 | 2.5 |\n",
    "| 50 | 2.0 |\n",
    "| 41 | 1.5 |\n",
    "| 32 | 1.0 |\n",
    "| 23 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-danger'>\n",
    "\n",
    "##### **Wichtige Hinweise**\n",
    "\n",
    "1. **Dieses Assignment wird benotet. Sie können Bonuspunkte für die Prüfung erhalten.**\n",
    "2. **Wenn es für uns offensichtlich ist, dass eine Aufgabe von einer anderen Quelle kopiert wurde und keine Eigenleistung erbracht wurde, vergeben wir keine Bonuspunkte. Formulieren Sie alle Antworten in eigenen Worten!**\n",
    "3. **Wenn LLMs (wie z.B. ChatGPT oder CoPilot) verwendet wurden, um Ihre Abgabe zu erstellen, geben Sie dies bitte an den jeweiligen Stellen an. Beachten Sie zudem die [AI-Policy](https://cogsys.uni-bamberg.de/teaching/ki-richtlinie.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für Aufgabe 3 muss auf eurem System auch [SWI Prolog](https://www.swi-prolog.org) installiert sein, sonst kommt es beim installieren der Abhängigkeiten zu einem Fehler!\n",
    "\n",
    "Du kannst _SWI Prolog_ auch über die gängigen Package-Manager installieren.\n",
    "\n",
    "- **Windows (chocolatey):** `choco install swi-prolog`\n",
    "- **macOS (Homebrew):** `brew install swi-prolog`\n",
    "\n",
    "**Wichtig:** Wenn du _SWI Prolog_ manuell installierst, darfst du nicht vergessen es auch in deiner `PATH` Variable einzutragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiert die benötigten Pakete mit dem akutell ausgewählten Python-Interpreter\n",
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | ID3 Implementierung\n",
    "\n",
    "_Für insgesamt 26 Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Herbst färben sich die Wälder golden und vielerorts beginnt die Pilzsaison. Zwischen den bunten Blättern finden sich zahlreiche Pilzarten. Manche davon sind essbar, andere hochgiftig. Ein automatisiertes Verfahren zur Bestimmung der Genießbarkeit kann helfen, gefährliche Verwechslungen zu vermeiden. Hierfür können Entscheidungsbäume (Decision Trees) verwendet werden.\n",
    "\n",
    "In dieser Aufgabe soll ein Entscheidungsbaum mithilfe des **ID3-Algorithmus** implementiert werden, um auf Grundlage von Pilzmerkmalen zu entscheiden, ob ein Pilz _genießbar_ oder _giftig_ ist. Ziel ist die Implementierung des **ID3-Algorithmus** zur Klassifikation von Pilzen auf Basis des Datensatzes `mushrooms.csv`. Der Algorithmus soll auf gegebenen Merkmalen einen Entscheidungsbaum lernen, der die Zielvariable `dangerous` möglichst genau vorhersagt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Import von Bibliotheken._** In der folgenden Zelle werden einige wichtige Bibliotheken importiert. Diese sind für die fortlaufende Implementierung notwendig. Sie sollen hier kurz erläutert werden:\n",
    "- `random` und `numpy`. Mit diesen beiden Bibliotheken werden _seeds_ gesetzt, um die Ergebnisse von Zufallsgeneratoren konsistent zu halten.\n",
    "- `pandas`. Aus pandas verwenden wir DataFrames, in denen die Datensätze liegen.\n",
    "- `typing.Any`. Wird benötigt für Type-Hints in den Spezifikationen der Methoden.\n",
    "- `sklearn.base.ClassifierMixin`. Stellt gemeinsame Funktionen für Klassifikationsmodelle bereit.\n",
    "- `sklearn.model_selection.train_test_split`. Teilt Datensätze in Trainings- und Testmengen auf.\n",
    "- `sklearn.metrics.accuracy_score`. Berechnet den Anteil korrekt klassifizierter Beispiele.\n",
    "\n",
    "**_An der nächsten Code Zelle muss nichts verändert werden._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:43.960330Z",
     "start_time": "2025-10-29T07:58:43.958436Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(2025)\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Import von Datensätzen._** In der folgenden Zelle wird der verwendete Beispieldatensatz geladen. Dieser liegt in `mushrooms.csv` und umfasst sechs kategorielle Entscheidungs- sowie ein binäres Zielattribut:\n",
    "\n",
    "- `habitat` (`forest`, `field`, `underwater`)\n",
    "- `hat_color` (`red`, `white`, `brown`)\n",
    "- `size` (`small`, `medium`, `large`)\n",
    "- `lamellae` (`wide`, `narrow`, `none`)\n",
    "- `hat_form` (`steep`, `flat`)\n",
    "- `stem` (`rough`, `smooth`)\n",
    "- **Target:** `dangerous` (`True`, `False`)\n",
    "\n",
    "Nachdem die `.csv` in einen `pd.DataFrame` geladen wurde, wird dieser in `X` (nur Entscheidungsattribute) und `y` (nur Zielattribut) geteilt. `X` und `y` werden weiterhin mit der `train_test_split()` Funktion in eine Trainingsmenge von $80\\%$ und eine Testmenge von $20\\%$ geteilt. **Wichtig:** mit `random_state=2025` wird sichergestellt, dass die Splits bei jeder Ausführung immer gleich sind. Scikit-Learn verwendet einen Seed, der nicht von `numpy` oder `random` gesetzt wird.\n",
    "\n",
    "**_An der nächsten Code Zelle muss nichts verändert werden._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:43.968992Z",
     "start_time": "2025-10-29T07:58:43.964704Z"
    }
   },
   "outputs": [],
   "source": [
    "mushrooms = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "X = mushrooms.drop('dangerous', axis=1)\n",
    "y = mushrooms['dangerous']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(01.1.1)** Berechnung von Entropy und Information Gain\n",
    "\n",
    "Für den Aufbau des Entscheidungsbaums werden zwei grundlegende Funktionen benötigt:\n",
    "\n",
    "1. `entropy(y)`: Berechnet den Grad der Unsicherheit in der Zielverteilung\n",
    "2. `information_gain(X, y, attribute)`: Misst, wie stark ein bestimmtes Attribut die Unsicherheit reduziert und somit für die Entscheidung im Baum relevant ist.\n",
    "\n",
    "_Diese Funktionen können im nachfolgenden Code-Block implementiert werden. Gerne könnt ihr dafür aber auch eine separate Python-Datei verwenden._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:43.974870Z",
     "start_time": "2025-10-29T07:58:43.972943Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(y: ArrayLike) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the entropy for the example subset `y`. Note that this method uses `y`, because entropy is always calculated with respect to the target attribute, so this method only needs the target attribute.\n",
    "\n",
    "    #### Parameters\n",
    "    - `y (ArrayLike)`: Subset of the target attribute for which to calculate entropy.\n",
    "\n",
    "    #### Returns\n",
    "    - `_ (float)`: Entropy calculated for `y`.\n",
    "    \"\"\"\n",
    "    # TODO: Compute the entropy of the example subset\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:43.980441Z",
     "start_time": "2025-10-29T07:58:43.978488Z"
    }
   },
   "outputs": [],
   "source": [
    "def information_gain(X: ArrayLike, y: ArrayLike, attribute: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the information gain for the attribute `attribute` given the target attribute `y`.\n",
    "\n",
    "    #### Parameters\n",
    "    - `X (ArrayLike`: The full dataset as array like structure (at this level of recursion).\n",
    "    - `y (ArrayLike)`: The corresponding target attribute.\n",
    "    - `attribute (str)`: The attribute for which to calculate the information gain.\n",
    "\n",
    "    #### Returns\n",
    "    - `_ (float)`: Information gain calculated for `attribute`.\n",
    "    \"\"\"\n",
    "    # TODO: Compute the information gain\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(01.1.2)** Implementierung des ID3-Algorithmus\n",
    "\n",
    "Im folgenden sollt ihr nun eine Klasse `DecisionTree` implementieren, welche den **ID3-Algorithmus** implementiert. Der Algorithmus soll rekursiv den Attributwert mit dem höchsten Information Gain auswählen und so schrittweise einen Entscheidungsbaum aufbauen. Die Baumstruktur kann frei gewählt werden (z.B. als verschachteltes Dictionary oder über eingene Klassen). Der trainierte Baum soll anschließend in Verbindung mit dem zuvor diskutierten `mushrooms.csv` Datensatz genutzt werden, um Vorhersagen über die _Genießbarkeit_ von Pilzen zu treffen.\n",
    "\n",
    "Die Klasse `DecisionTree` soll dabei von `ClassifierMixin` erben. Dabei sind die Methoden `fit` und `predict` notwendig. Dadurch kann euer Entscheidungsbaum später problemlos in Pipelines, die auf dem `sklearn`-Framework basieren, verwendet werden.\n",
    "\n",
    "_Es ist nicht notwendig die Implementierung in diesem Jupyter Notebook durchzuführen. Alternativ könnt ihr auch separate Python Dateien verwenden._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:43.988511Z",
     "start_time": "2025-10-29T07:58:43.984323Z"
    }
   },
   "outputs": [],
   "source": [
    "### ID3 Implementation ###\n",
    "\n",
    "class DecisionTree(ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Implements a tree data structure and both decision tree training using ID3 and decision tree inference. Also includes methods for calculating entropy and information gain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default_class: Any = None):\n",
    "        \"\"\"\n",
    "        Decision Tree constructor\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, X: ArrayLike, y: ArrayLike):\n",
    "        \"\"\"\n",
    "        Fit the decision tree to the dataset `X` with target attribute `y`.\n",
    "\n",
    "        #### Parameters\n",
    "        - `X (v)`: The full dataset.\n",
    "        - `y (ArrayLike)`: The corresponding target attribute.\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def id3(self, X: ArrayLike, y: ArrayLike) -> dict[dict] | Any:\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree using the ID3 algorithm.\n",
    "\n",
    "        #### Parameters\n",
    "        - `X (ArrayLike)`: The full dataset (at this level of recursion).\n",
    "        - `y (ArrayLike)`: The corresponding target attribute.\n",
    "\n",
    "        #### Returns\n",
    "        - `_ (dict[dict] | Any)`: The resulting Decision Tree as a nested dictionary. Each node is either a nested dictionary (internal node) or a leaf node with the predicted value.\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def predict(self, X: ArrayLike) -> ArrayLike:\n",
    "        \"\"\"\n",
    "        Predict the target attribute for the dataset `X`.\n",
    "\n",
    "        #### Parameters\n",
    "        - `X (ArrayLike)`: The dataset for which to predict the target attribute.\n",
    "\n",
    "        #### Returns\n",
    "        - `_ (ArrayLike)`: The predicted target attributes.\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(01.1.3)** Training\n",
    "\n",
    "Nach erfolgreicher Implementierung soll der Entscheidungsbaum auf den `mushrooms.csv` Datensatz angewandt werden. Das bedeutet, dass in den folgenden Code Zellen der `DecisionTree` auf den `mushrooms.csv` Datensatz angewendet werden soll. Dabei sind die folgenden Schritte notwendig:\n",
    "\n",
    "1. **Training des Entscheidungsbaums** mit den vorbereiteten Trainingsdaten\n",
    "2. **Vorhersage** der Klassenzugehörigkeit auf den Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:44.239648Z",
     "start_time": "2025-10-29T07:58:43.992332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | ID3 Evaluation mit k-Fold-Cross-Validation\n",
    "\n",
    "_Für insgesamt 20 Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem ihr im vorherigen Abschnitt den **ID3-Algorithmus** umgesetzt habt, soll der entwickelte Entscheidungsbaum (`DecisionTree`) nun bewertet werden. Ziel ist es, die Modellgüte des Baums zu bestimmen und zu überprüfen, wie stabil die erzielten Ergebnisse über verschiedene Datenaufteilungen hinweg ausfallen.\n",
    "\n",
    "#### **(01.2.1)** k-Fold-Corss-Validation\n",
    "\n",
    "Hierzu soll eine **k-Fold-Corss-Validation** verwendet werden. Diese Methode teilt den Datensatz in mehrere Teilmengen (Folds) auf und ermöglicht so, den Entscheidungsbaum mehrfach mit unterschiedlichen Trainings- und Testdaten zu evaluieren. Durch das wiederholte Trainieren und Testen entsteht ein umfassenderes Bild der Modellleistung, als es mit einer einmaligen Aufteilung möglich wäre.\n",
    "\n",
    "**Dabei ist die Verwendung von `KFold` oder ähnlichen Hilfsklassen aus scikit-lear ausgeschlossen. Die Aufteilung der Daten in Folds soll eigenständig erfolgen.**\n",
    "\n",
    "Für diese Aufgabe sollen zwei Funktionen entwickelt werden, die gemeinsam den Evaluationsprozess automatisieren:\n",
    "\n",
    "1. `evaluate_fold`. Diese Funktion übernimmt die Bewertung eines einzelnen Folds. Sie trainiert den vorhandenen Entscheidungsbaum (`DecisionTree`) auf den Trainingsdaten und prüft anschließend dessen Accuracy auf den Testdaten. Sollte die eigene Implementierung der `DecisionTree` Klasse nicht lauffähig sein, kann auf den `DecisionTreeClassifier` aus `scikit-learn` zurückgegriffen werden, um den Evaluationsprozess dennoch vollständig durchführen zu können. In diesem Fall müssen kategoriale Eingabewerte vorab kodiert werden.\n",
    "2. `run_kfold_evaluation`. Diese Funktion steuert den gesammten Ablauf der Cross-Validation. Sie erzeugt die $k$-Folds ($k=5$) des Datensatzes. Dabei sollen die Daten zunächst zufällig durchmischt werden, um eine faire Verteilung der Klassen zu gewährleisten. Anschließend werden die Indexgruppen der fünf Folds gebildet, wobei jeweils ein Fold als Test- und die übrigen als Trainingsdaten dienen. Für jeden Fold wird die zuvor definierte `evaluate_fold` Funktion aufgerufen. Alle Einzelergebnisse sollen in einer Tabelle gesammelt werden. Die resultierende Tabelle soll Angaben zu Fold-Nummer, Trainings- und Testgrößen, verwendeter Methoden und Accuracy enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:44.246584Z",
     "start_time": "2025-10-29T07:58:44.243947Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_fold(\n",
    "        X_train: ArrayLike,\n",
    "        X_test: ArrayLike,\n",
    "        y_train: ArrayLike,\n",
    "        y_test: ArrayLike,\n",
    "        fold: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates a single fold during a cross-validation process. The function trains the decision tree on the given training data, makes\n",
    "    predictions on the test data, and calculates the accuracy of these predictions.\n",
    "\n",
    "    #### Parameters\n",
    "    - `X_train (ArrayLike)`: Training feature dataset.\n",
    "    - `X_test (ArrayLike)`: Test feature dataset.\n",
    "    - `y_train (ArrayLike)`: Training target labels.\n",
    "    - `y_test (ArrayLike)`: Test target labels.\n",
    "    - `fold (int)`: Fold identifier.\n",
    "\n",
    "    #### Returns\n",
    "    - `dict`: A dictionary containing:\n",
    "        - `'fold' (int)`: The fold identifier.\n",
    "        - `'train_size' (int)`: Number of samples in the training set.\n",
    "        - `'test_size' (int)`: Number of samples in the test set.\n",
    "        - `'accuracy' (float)`: Accuracy score for the current fold.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the evaluation of a single fold.\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_kfold_evaluation(X: ArrayLike, y: ArrayLike, k=5, random_state=2025) -> ArrayLike:\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation on the given dataset using a custom decision tree evaluator.\n",
    "\n",
    "    The function splits the dataset into `k` folds, trains and tests a decision tree model on each fold using the `evaluate_fold` function, and aggregates the results (e.g., accuracy) into a single DataFrame.\n",
    "\n",
    "    #### Parameters\n",
    "    - `X (ArrayLike)`: Feature dataset containing independent variables.\n",
    "    - `y (ArrayLike)`: Target variable corresponding to `X`.\n",
    "    - `k (int, default=5)`: Number of folds to use for cross-validation.\n",
    "    - `random_state (int, default=2025)`: Random seed for reproducibility of fold splits.\n",
    "\n",
    "    #### Returns\n",
    "    - `ArrayLike`: A DataFrame summarizing the evaluation results for each fold,\n",
    "      containing the following columns:\n",
    "        - `'fold' (int)`: The fold identifier.\n",
    "        - `'train_size' (int)`: Number of training samples in that fold.\n",
    "        - `'test_size' (int)`: Number of test samples in that fold.\n",
    "        - `'accuracy' (float)`: Accuracy score achieved on the test set.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the k-fold cross-validation process.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(01.2.2)** Interpretation der Ergebnisse\n",
    "\n",
    "Die folgende Zelle führt die zuvor implementierte k-Fold-Evaluation aus und gibt eine tabellarische Übersicht der Ergebnisse aus.\n",
    "\n",
    "**_An der nächsten Code Zelle muss nichts verändert werden._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:58:45.508869Z",
     "start_time": "2025-10-29T07:58:44.252896Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = run_kfold_evaluation(X, y, k=5)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was fällt eucht bei den Ergebnissen auf? Beschreibt kurz, welche Muster oder Auffälligkeiten ihr erkennen könnt. Geht dabei insbesondere darauf ein, was die Resultate über die Generalisierungsfähigkeit des Modells aussagen. Nehmt dabei Bezug auf das Training aus Teilaufgabe 0.1.1.3. Was sagen die Ergebnisse über die Implementierung euerer `DecisionTree` Klasse aus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Interpretation der Ergebnisse:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ist die Accuracy hier eine geeignete Metrik? Welche Alternativen gäbe es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Diskussion über Metriken:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 | ILP\n",
    "_Für insgesamt 16 Punkte_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Hexe, hat ihr ganzes Leben damit verbracht, Rituale zu dokumentieren. In ihrem digitalisierten Ritual-Journal sind über siebzig Rituale festgehalten, von denen einige gefährliche Monster beschworen, während andere harmlos verliefen. Jedes Ritual ist genau beschrieben: Die verwendeten Zutaten, der Ort, die Mondphase und Besonderheiten wie die Frage, ob die Beschwörungsformeln rückwärts gesprochen wurden oder das Ritual um Mitternacht stattfand.\n",
    "\n",
    "Eure Aufgabe besteht darin, ein Python-Programm zu entwickeln, das mithilfe von `janus_swi` die Prolog-Fakten aus der Datei `rituals.pl` abfragt und analysiert, welche Bedingungen besonders stark mit gefährlichen Beschwörungen in Zusammenhang stehen**.\n",
    "Hierzu soll der aus der Vorlesung bekannte _FoilGain_ berechnet werden.\n",
    "\n",
    "Die FoilGain-Formel lautet:\n",
    "\n",
    "$$\n",
    "\\text{FoilGain}(L, R) = t \\cdot \\Big(\\log_2\\frac{p_1}{p_1+n_1} - \\log_2\\frac{p_0}{p_0+n_0}\\Big)\n",
    "$$\n",
    "\n",
    "mit\n",
    "\n",
    "- $L$ als neuem Literal, das zu ($R$) hinzugefügt wurde, um die neue Regel ($R'$) zu erhalten,\n",
    "- $t$ als die Anzahl der positiven Beispiele der Regel ($R$), die auch noch von ($R'$) abgedeckt sind,\n",
    "- $p_0$ als Anzahl der positiven Beispiele, die **vor** Hinzufügen von ($L$) abgedeckt werden,\n",
    "- $n_0$ als Anzahl der negativen Beispiele, die **vor** Hinzufügen von ($L$) abgedeckt werden,\n",
    "- $p_1$ als Anzahl der positiven Beispiele, die **nach** Hinzufügen von ($L$) abgedeckt werden,\n",
    "- $n_1$ als Anzahl der negativen Beispiele, die **nach** Hinzufügen von ($L$) abgedeckt werden.\n",
    "\n",
    "Die FoilGain-Formel bewertet also, _wie stark eine neue Bedingung (Literal)_ die Unterscheidung zwischen gefährlichen und harmlosen Ritualen verbessert.\n",
    "Ein hoher FoilGain-Wert bedeutet, dass das Literal den Anteil gefährlicher Rituale unter den abgedeckten Beispielen deutlich erhöht – und damit ein wichtiger Hinweis auf gefährliche Beschwörungsbedingungen ist.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Vorgehensweise und Anforderungen für die Implementierung:**\n",
    "\n",
    "* Nutzt `janus_swi`, um die Fakten in `rituals.pl` abzufragen.\n",
    "\n",
    "* Implementiert eine Funktion `calculate_foil_gain(p0, n0, p1, n1)`, die den FoilGain nach der angegebenen Formel berechnet.\n",
    "\n",
    "* Erstellt eine Hilfsfunktion, die für eine beliebige Bedingung (Literal) zählt, wie viele Rituale gefährlich und wie viele sicher sind.\n",
    "\n",
    "* Die möglichen Bedingungen (Kandidaten-Literale) dürfen _nicht fest im Code hinterlegt_ sein. Stattdessen sollen sie  _automatisch_ aus den vorhandenen Fakten in `rituals.pl` generiert werden.\n",
    "  Dadurch bleibt das Programm erweiterbar, falls neue `ingredients`, `moon_phases` oder `locations` hinzukommen.\n",
    "\n",
    "- Die Prolog-Abfragen können z. B. so aussehen:\n",
    "  `\"summoned(R, monster).\"` für gefährliche Rituale oder `\"ingredient(R, nightshade).\"` als zusätzliche Bedingung.\n",
    "  Somit gelten Rituale mit `\"summoned(R, monster).\"` als _positive Beispiele_, und solche mit `\"summoned(R, nothing).\"` als _negative Beispiele_.\n",
    "\n",
    "- Implementiert anschließend eine Routine, die _alle möglichen Kandidaten-Literale automatisch erzeugt_ und für jedes Literal:\n",
    "  1. ($p_0$, $n_0$, $p_1$, $n_1$) ermittelt,\n",
    "  2. den FoilGain berechnet,\n",
    "  3. das Ergebnis (Literal + FoilGain-Wert) in einer Liste oder Tabelle speichert.\n",
    "\n",
    "- Sortiert alle berechneten Bedingungen nach ihrem FoilGain-Wert.\n",
    "\n",
    "- Gebt am Ende die _fünf gefährlichsten Bedingungen_ (mit dem höchsten FoilGain) aus.\n",
    "\n",
    "- Testet eure Implementierung exemplarisch an einzelnen Bedingungen, z. B. bestimmten Zutaten, Mondphasen, Orten oder Spezialattributen (`spoken_backwards`, `performed_at_midnight`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Aufgabe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
